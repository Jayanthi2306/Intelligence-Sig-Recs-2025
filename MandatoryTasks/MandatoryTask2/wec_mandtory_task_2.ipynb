{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Load the train data ."
      ],
      "metadata": {
        "id": "8mzZyUpYjhI8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "\n",
        "df=pd.read_csv(\"train_data.csv\")\n",
        "\n",
        "print(df.head())\n",
        "print(df.shape)\n"
      ],
      "metadata": {
        "id": "VV2u6S6GXLuU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the dataset is very large we are taking only 1st 50k rows to speed up the process."
      ],
      "metadata": {
        "id": "U7xkLzpSX2Ty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=df.iloc[:50000,:]\n",
        "print(data.head())\n",
        "label=data[\"y\"]\n",
        "features = data.drop(\"y\", axis=1)"
      ],
      "metadata": {
        "id": "J0fC4unTXOBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the data is in same scale almost so there is no need of scaling.1st checking its accuracy with linear model."
      ],
      "metadata": {
        "id": "16GdoSVlYH1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "X_train, X_test, y_train, y_test = train_test_split(features,label, test_size=0.2, random_state=42)\n",
        "\n",
        "linear_model = LinearRegression()\n",
        "linear_model.fit(X_train, y_train)\n",
        "y_pred_linear = linear_model.predict(X_test)\n",
        "print(\"r2 score\",r2_score(y_test,y_pred_linear))"
      ],
      "metadata": {
        "id": "WAcyWvIoYGrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the accuracy is very bad i understand the data is not linear so decided to plot the data.after the plot i undersatnd there is contribution of w to the output y. Since it is same irrespective of the value of x and y."
      ],
      "metadata": {
        "id": "-wxKsRdjYOuz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "fig = plt.figure(figsize=(10, 7))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "scatter = ax.scatter(\n",
        "    data['w'], data['x'], data['y'],\n",
        "    c=data['y'],\n",
        "    cmap='viridis',\n",
        "    s=50,\n",
        "    alpha=0.8,\n",
        "    edgecolor='k'\n",
        ")\n",
        "\n",
        "ax.set_xlabel('w', fontsize=12)\n",
        "ax.set_ylabel('x', fontsize=12)\n",
        "ax.set_zlabel('y (Target)', fontsize=12)\n",
        "ax.set_title('3D Visualization - Multinomial Logistic Regression', fontsize=14)\n",
        "\n",
        "fig.colorbar(scatter, ax=ax, label='Class Label')\n",
        "ax.view_init(elev=25, azim=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SzZbMsnLYc29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the accuracy is very bad in linear regression now i am checking with xgboost model which performs very good on non linear data."
      ],
      "metadata": {
        "id": "wq1dD3n-Y5eO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, random_state=42)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "y_pred_xgb = xgb_model.predict(X_test)\n",
        "print(\"r2 score\",r2_score(y_test,y_pred_xgb))"
      ],
      "metadata": {
        "id": "yNdhCniuYCR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Again checking with random forest classifier. Since i gave the best accuarcy i am stopping at this point."
      ],
      "metadata": {
        "id": "o60c91DmZIzO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "print(\"r2 score\",r2_score(y_test,y_pred_rf))"
      ],
      "metadata": {
        "id": "X547VfPbZUbw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}