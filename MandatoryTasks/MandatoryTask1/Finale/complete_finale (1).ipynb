{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate --quiet\n"
      ],
      "metadata": {
        "id": "uKPyL-32ph-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XyrmY4e5pfXX"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import os\n",
        "import csv\n",
        "import numpy as np\n",
        "from typing import List, Tuple, Dict\n",
        "\n",
        "import torch\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForQuestionAnswering,\n",
        "    pipeline as hf_pipeline,\n",
        "    MarianMTModel,\n",
        "    MarianTokenizer\n",
        ")\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from datasets import load_dataset\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import evaluate\n",
        "from collections import defaultdict\n",
        "\n",
        "DEVICE = 0 if torch.cuda.is_available() else -1\n",
        "\n",
        "\n",
        "def create_context_embeddings(dataset_name: str = \"lucadiliello/newsqa\",\n",
        "                              split: str = \"validation\",\n",
        "                              model_name: str = \"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "                              out_csv: str = \"context_embeddings.csv\",\n",
        "                              max_examples: int = 2000):\n",
        "    \"\"\"\n",
        "    Loads dataset contexts, embeds them with a SentenceTransformer, and writes CSV rows:\n",
        "      id, context_text, embedding_vector_json\n",
        "    \"\"\"\n",
        "    ds = load_dataset(dataset_name, split=split)\n",
        "    print(f\"Loaded {len(ds)} examples from {dataset_name}/{split}\")\n",
        "    texts = []\n",
        "    ids = []\n",
        "    for i, ex in enumerate(ds):\n",
        "        if i >= max_examples:\n",
        "            break\n",
        "        txt = ex.get(\"context\") or \"\"\n",
        "        if not txt.strip():\n",
        "            continue\n",
        "        ids.append(str(i))\n",
        "        texts.append(txt)\n",
        "\n",
        "    embedder = SentenceTransformer(model_name, device='cuda' if DEVICE == 0 else 'cpu')\n",
        "    print(f\"Embedding {len(texts)} contexts with {model_name} ...\")\n",
        "    vectors = embedder.encode(texts, show_progress_bar=True, convert_to_numpy=True)\n",
        "    with open(out_csv, \"w\", newline='', encoding='utf-8') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([\"id\", \"context\", \"embedding\"])\n",
        "        for i, (id_, ctxt, vec) in enumerate(zip(ids, texts, vectors)):\n",
        "            vec_str = \" \".join(map(str, vec.tolist()))\n",
        "            writer.writerow([id_, ctxt.replace(\"\\n\", \" \"), vec_str])\n",
        "    print(f\"Wrote embeddings to {out_csv}\")\n",
        "    return out_csv, ids, texts, vectors\n",
        "\n",
        "def load_embeddings_from_csv(csv_path: str) -> Tuple[List[str], List[str], np.ndarray]:\n",
        "    ids, contexts, vecs = [], [], []\n",
        "    with open(csv_path, newline='', encoding='utf-8') as f:\n",
        "        reader = csv.DictReader(f)\n",
        "        for row in reader:\n",
        "            ids.append(row[\"id\"])\n",
        "            contexts.append(row[\"context\"])\n",
        "            vec = np.fromstring(row[\"embedding\"], sep=\" \")\n",
        "            vecs.append(vec)\n",
        "    return ids, contexts, np.vstack(vecs)\n",
        "\n",
        "\n",
        "def semantic_search(query: str, contexts: List[str], vectors: np.ndarray, embedder: SentenceTransformer, top_k: int = 3):\n",
        "    q_vec = embedder.encode([query], convert_to_numpy=True)\n",
        "    sims = cosine_similarity(q_vec, vectors)[0]\n",
        "    topk_idx = np.argsort(sims)[::-1][:top_k]\n",
        "    return [(int(i), contexts[int(i)], float(sims[int(i)])) for i in topk_idx]\n",
        "\n",
        "\n",
        "def load_qa_model(model_name: str = \"deepset/roberta-base-squad2\"):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
        "    model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
        "    qa = hf_pipeline(\"question-answering\", model=model, tokenizer=tokenizer, device=DEVICE)\n",
        "    return qa\n",
        "\n",
        "\n",
        "def load_translation_model(model_name: str = \"Helsinki-NLP/opus-mt-en-fr\"):\n",
        "    tok = MarianTokenizer.from_pretrained(model_name)\n",
        "    mod = MarianMTModel.from_pretrained(model_name)\n",
        "    device = torch.device(\"cuda\" if DEVICE == 0 else \"cpu\")\n",
        "    mod = mod.to(device)\n",
        "    return tok, mod\n",
        "\n",
        "def translate_en_to_fr(texts: List[str], tokenizer: MarianTokenizer, model: MarianMTModel, max_length: int = 256) -> List[str]:\n",
        "    inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_length)\n",
        "    inputs = {k: v.to(model.device) for k,v in inputs.items()}\n",
        "    translated = model.generate(**inputs, max_length=max_length, num_beams=4, early_stopping=True)\n",
        "    decoded = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
        "    return decoded\n",
        "\n",
        "\n",
        "class EnglishToFrenchQA:\n",
        "    def __init__(self,\n",
        "                 embedding_csv: str = None,\n",
        "                 embedding_model_name: str = \"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "                 qa_model_name: str = \"deepset/roberta-base-squad2\",\n",
        "                 mt_model_name: str = \"Helsinki-NLP/opus-mt-en-fr\"):\n",
        "\n",
        "        if embedding_csv and os.path.exists(embedding_csv):\n",
        "            self.ids, self.contexts, self.vectors = load_embeddings_from_csv(embedding_csv)\n",
        "            self.embedder = SentenceTransformer(embedding_model_name, device='cuda' if DEVICE == 0 else 'cpu')\n",
        "        else:\n",
        "            raise ValueError(\"Please provide an embeddings CSV (create with create_context_embeddings).\")\n",
        "\n",
        "        self.qa = load_qa_model(qa_model_name)\n",
        "        self.mt_tok, self.mt_model = load_translation_model(mt_model_name)\n",
        "\n",
        "    def answer(self, english_question: str, top_k_contexts: int = 3) -> Dict:\n",
        "\n",
        "        top_ctxs = semantic_search(english_question, self.contexts, self.vectors, self.embedder, top_k=top_k_contexts)\n",
        "        candidates = []\n",
        "        for idx, ctxt, score in top_ctxs:\n",
        "            try:\n",
        "\n",
        "                out = self.qa(question=english_question, context=ctxt, topk=1)\n",
        "\n",
        "                if isinstance(out, list):\n",
        "                    out = out[0] if len(out)>0 else {\"answer\": \"\", \"score\": 0.0, \"start\": 0, \"end\": 0}\n",
        "                answer_text = out.get(\"answer\", \"\")\n",
        "                cand_score = float(out.get(\"score\", 0.0))\n",
        "            except Exception as e:\n",
        "                answer_text = \"\"\n",
        "                cand_score = 0.0\n",
        "            candidates.append({\n",
        "                \"context_id\": idx,\n",
        "                \"context\": ctxt,\n",
        "                \"retrieval_score\": score,\n",
        "                \"answer_en\": answer_text,\n",
        "                \"qa_score\": cand_score\n",
        "            })\n",
        "\n",
        "        best = max(candidates, key=lambda x: (x[\"qa_score\"], len(x[\"answer_en\"])))\n",
        "        if not best[\"answer_en\"].strip():\n",
        "            answer_fr = \"\"\n",
        "        else:\n",
        "            answer_fr = translate_en_to_fr([best[\"answer_en\"]], self.mt_tok, self.mt_model)[0]\n",
        "        best[\"answer_fr\"] = answer_fr\n",
        "        return best\n",
        "\n",
        "\n",
        "def evaluate_on_dataset(qa_system: EnglishToFrenchQA, dataset_name=\"lucadiliello/newsqa\", split=\"validation\", n_examples=200):\n",
        "    ds = load_dataset(dataset_name, split=split)\n",
        "    metric = evaluate.load(\"squad\")\n",
        "    preds, refs = [], []\n",
        "    for i, ex in enumerate(ds):\n",
        "        if i >= n_examples:\n",
        "            break\n",
        "        question = ex.get(\"question\", \"\").strip()\n",
        "        context = ex.get(\"context\", \"\")\n",
        "        res = qa_system.answer(question, top_k_contexts=3)\n",
        "        pred_text = res[\"answer_en\"]\n",
        "        preds.append({\"id\": str(i), \"prediction_text\": pred_text})\n",
        "        ans_obj = ex.get(\"answers\", {})\n",
        "        if isinstance(ans_obj, dict):\n",
        "            texts = ans_obj.get(\"text\", []) or [\"\"]\n",
        "        elif isinstance(ans_obj, list) and len(ans_obj)>0:\n",
        "            first = ans_obj[0]\n",
        "            texts = first.get(\"text\", []) if isinstance(first, dict) else [\"\"]\n",
        "        else:\n",
        "            texts = [\"\"]\n",
        "        refs.append({\"id\": str(i), \"answers\": {\"text\": texts, \"answer_start\": [0]*len(texts)}})\n",
        "\n",
        "    ids_ok = [p[\"id\"] for p in preds]\n",
        "    refs = [r for r in refs if r[\"id\"] in ids_ok]\n",
        "    results = metric.compute(predictions=preds, references=refs)\n",
        "    return results\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    csv_path, ids, contexts, vectors = None, None, None, None\n",
        "    emb_csv = \"context_embeddings.csv\"\n",
        "    if not os.path.exists(emb_csv):\n",
        "        create_context_embeddings(split=\"validation\", max_examples=1000, out_csv=emb_csv)\n",
        "    qa_system = EnglishToFrenchQA(embedding_csv=emb_csv)\n",
        "    examples = [\n",
        "        \"What did the mayor say about the new bridge?\",\n",
        "        \"Why did the CEO resign?\"\n",
        "    ]\n",
        "    for q in examples:\n",
        "        resp = qa_system.answer(q, top_k_contexts=4)\n",
        "        print(\"Q:\", q)\n",
        "        print(\"Retrieved context id:\", resp[\"context_id\"])\n",
        "        print(\"Answer (EN):\", resp[\"answer_en\"])\n",
        "        print(\"Answer (FR):\", resp[\"answer_fr\"])\n",
        "        print(\"---\")\n",
        "\n"
      ]
    }
  ]
}