{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "id": "59nJeuQO3tEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code loads the NewsQA dataset, cleans and tokenizes the text, trains both CBOW and Skip-gram Word2Vec models, and saves the learned word embeddings to CSV files"
      ],
      "metadata": {
        "id": "YEIrpF1W4S86"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "importing all the necessary libraries and loding the newsQA dataset."
      ],
      "metadata": {
        "id": "Qt_xj_1JRDq5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mY97o04GjwxO",
        "outputId": "6f56416d-1d27-4313-f4f8-3d427d8efbbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saved successfully\n",
            "saved successfully\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from gensim.models import Word2Vec\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "dataset = load_dataset(\"lucadiliello/newsqa\",split=\"train\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "preprocessing and tokenizing the data"
      ],
      "metadata": {
        "id": "VpqrZT4mRZqv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = dataset[\"context\"][:1000]\n",
        "\n",
        "tokenized_sentences = []\n",
        "for text in texts:\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
        "    tokens = word_tokenize(text)\n",
        "    if tokens:\n",
        "        tokenized_sentences.append(tokens)"
      ],
      "metadata": {
        "id": "CR0pm7NwQ3ec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making word embeddings using cbow(continuous bag of words) method.Cbow method is a type of word2vec method."
      ],
      "metadata": {
        "id": "kYZ6E9PLRtks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "cbow_model = Word2Vec(sentences=tokenized_sentences, vector_size=100, window=5, min_count=2, sg=0, epochs=5)\n",
        "words = list(cbow_model.wv.key_to_index.keys())\n",
        "vectors = [cbow_model.wv[word].tolist() for word in words]\n",
        "df = pd.DataFrame({'word': words, 'embedding': vectors})\n",
        "df.to_csv(\"cbow_embeddings.csv\", index=False)\n",
        "print(\"saved successfully\")"
      ],
      "metadata": {
        "id": "N-ZC4liHQ8PJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another word2vec methos- skipgram model."
      ],
      "metadata": {
        "id": "wWtUFoRWSBZr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "skipgram_model = Word2Vec(sentences=tokenized_sentences, vector_size=100, window=5, min_count=2, sg=1, epochs=5)\n",
        "words = list(skipgram_model.wv.key_to_index.keys())\n",
        "vectors = [skipgram_model.wv[word].tolist() for word in words]\n",
        "df = pd.DataFrame({'word': words, 'embedding': vectors})\n",
        "df.to_csv(\"skipgram_model.csv\", index=False)\n",
        "print(\"saved successfully\")"
      ],
      "metadata": {
        "id": "p8dsaRCgQ_hU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "saving manually the embedding files"
      ],
      "metadata": {
        "id": "rsne-ZmJSNnc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"cbow_embeddings.csv\")\n",
        "files.download(\"skipgram_model.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "MYk5_uve1tAn",
        "outputId": "26790339-1af1-4918-ab72-a827462152f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5fcc1460-90b2-4646-bdaa-f78d9a320cd5\", \"cbow_embeddings.csv\", 22188769)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a629c712-7c62-4d5e-8458-69ef8cc17647\", \"skipgram_model.csv\", 21825340)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}